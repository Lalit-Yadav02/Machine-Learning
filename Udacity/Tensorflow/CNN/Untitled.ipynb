{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-468ca9d84ac9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/lality/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/lality/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/lality/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/lality/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lality/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lality/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 - Loss: 47474.1328 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch   2 - Loss: 40093.6875 Validation Accuracy: 0.121094\n",
      "Epoch  1, Batch   3 - Loss: 35665.7656 Validation Accuracy: 0.144531\n",
      "Epoch  1, Batch   4 - Loss: 31313.9805 Validation Accuracy: 0.144531\n",
      "Epoch  1, Batch   5 - Loss: 30236.8984 Validation Accuracy: 0.179688\n",
      "Epoch  1, Batch   6 - Loss: 24673.1719 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch   7 - Loss: 26796.8008 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch   8 - Loss: 26232.9785 Validation Accuracy: 0.195312\n",
      "Epoch  1, Batch   9 - Loss: 23943.9102 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  10 - Loss: 21993.4648 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  11 - Loss: 21505.9805 Validation Accuracy: 0.214844\n",
      "Epoch  1, Batch  12 - Loss: 21926.6387 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  13 - Loss: 21610.9102 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  14 - Loss: 19969.6953 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  15 - Loss: 19708.4902 Validation Accuracy: 0.257812\n",
      "Epoch  1, Batch  16 - Loss: 21303.5000 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  17 - Loss: 20648.2578 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  18 - Loss: 14710.2969 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  19 - Loss: 18145.3379 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  20 - Loss: 17302.9688 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  21 - Loss: 16761.5195 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  22 - Loss: 14587.3242 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  23 - Loss: 16277.9102 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  24 - Loss: 14677.6426 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  25 - Loss: 14884.9023 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  26 - Loss: 17587.2109 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  27 - Loss: 14156.5156 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  28 - Loss: 14080.9121 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  29 - Loss: 13975.3516 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  30 - Loss: 14593.5039 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  31 - Loss: 11955.9609 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  32 - Loss: 11306.4160 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  33 - Loss: 12848.6152 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  34 - Loss: 15204.8516 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  35 - Loss: 13312.8506 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  36 - Loss: 11022.8428 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  37 - Loss: 12934.4678 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  38 - Loss: 10859.6904 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  39 - Loss: 12572.7285 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  40 - Loss: 11041.0117 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  41 - Loss: 12469.4492 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  42 - Loss: 11151.4766 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  43 - Loss: 11440.4004 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  44 - Loss:  8865.3047 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  45 - Loss: 12243.0137 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  46 - Loss:  9506.5977 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  47 - Loss:  8657.7402 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  48 - Loss: 10180.5391 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  49 - Loss:  9623.2637 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  50 - Loss:  8664.1250 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  51 - Loss:  9706.7461 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  52 - Loss: 11158.0312 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  53 - Loss:  7509.5283 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  54 - Loss:  7097.8262 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  55 - Loss:  7905.8916 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  56 - Loss:  9853.5820 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  57 - Loss:  8813.0605 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  58 - Loss:  8233.0840 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  59 - Loss:  9091.0859 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  60 - Loss:  8439.7832 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  61 - Loss:  8586.8730 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  62 - Loss:  9315.5352 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  63 - Loss:  9258.3643 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  64 - Loss:  6582.8232 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  65 - Loss:  7779.7178 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  66 - Loss:  6291.5571 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  67 - Loss:  6172.7275 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  68 - Loss:  6833.5049 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  69 - Loss:  8268.7334 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  70 - Loss:  7206.6104 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  71 - Loss:  7289.4106 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  72 - Loss:  7949.8848 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  73 - Loss:  7355.9043 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  74 - Loss:  7489.6470 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  75 - Loss:  7910.6401 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  76 - Loss:  7534.7593 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  77 - Loss:  8921.6484 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  78 - Loss:  6033.0034 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  79 - Loss:  6526.2163 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  80 - Loss:  6852.5859 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  81 - Loss:  6736.1982 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  82 - Loss:  6238.2690 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  83 - Loss:  5747.0029 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  84 - Loss:  5025.9805 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  85 - Loss:  7501.3242 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  86 - Loss:  6321.7588 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch  87 - Loss:  6625.2798 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  88 - Loss:  5941.9053 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch  89 - Loss:  6264.4932 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  90 - Loss:  5647.1855 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  91 - Loss:  5460.2520 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch  92 - Loss:  6630.3818 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch  93 - Loss:  4471.4385 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  94 - Loss:  5281.8496 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  95 - Loss:  6294.4194 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  96 - Loss:  6294.3447 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch  97 - Loss:  6739.2393 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch  98 - Loss:  6516.7344 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  99 - Loss:  5028.6543 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 100 - Loss:  5350.7275 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 101 - Loss:  6790.0347 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 102 - Loss:  4413.4199 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 103 - Loss:  5282.4712 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 104 - Loss:  5655.4365 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 105 - Loss:  4809.1943 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 106 - Loss:  5212.8662 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 107 - Loss:  6314.6006 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 108 - Loss:  6189.7798 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 109 - Loss:  4877.9375 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 110 - Loss:  4824.0674 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 111 - Loss:  5009.7749 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 112 - Loss:  3928.4873 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 113 - Loss:  5379.1943 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 114 - Loss:  4381.3271 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 115 - Loss:  3755.1074 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 116 - Loss:  5365.4756 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 117 - Loss:  5115.9702 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 118 - Loss:  5405.5742 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 119 - Loss:  4777.8672 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 120 - Loss:  4473.6128 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 121 - Loss:  5208.6045 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 122 - Loss:  3808.5747 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 123 - Loss:  3891.3472 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 124 - Loss:  5193.4736 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 125 - Loss:  3878.1738 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 126 - Loss:  4453.1260 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 127 - Loss:  4863.4395 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 128 - Loss:  4094.1240 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 129 - Loss:  3425.6838 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 130 - Loss:  5283.3740 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 131 - Loss:  4695.0488 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 132 - Loss:  3905.4080 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 133 - Loss:  4119.5693 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 134 - Loss:  5491.8164 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 135 - Loss:  4995.2539 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 136 - Loss:  4629.2871 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 137 - Loss:  4077.8665 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 138 - Loss:  4563.5229 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 139 - Loss:  3410.1367 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 140 - Loss:  3935.5103 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 141 - Loss:  3451.8521 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 142 - Loss:  5121.6826 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 143 - Loss:  3690.0586 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 144 - Loss:  4610.9541 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 145 - Loss:  5080.7900 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 146 - Loss:  2940.5586 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 147 - Loss:  4018.0620 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 148 - Loss:  3788.2634 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 149 - Loss:  5417.9219 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 150 - Loss:  4444.0601 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 151 - Loss:  5345.1406 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 152 - Loss:  3825.8313 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 153 - Loss:  4210.2178 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 154 - Loss:  3694.2903 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 155 - Loss:  3571.9463 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 156 - Loss:  3695.1726 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 157 - Loss:  3569.7329 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 158 - Loss:  3485.6384 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 159 - Loss:  3649.3228 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 160 - Loss:  4456.6562 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 161 - Loss:  3840.2217 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 162 - Loss:  3728.3733 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 163 - Loss:  3969.8594 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 164 - Loss:  4085.6396 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 165 - Loss:  3909.3972 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 166 - Loss:  4438.0024 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 167 - Loss:  2822.0676 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 168 - Loss:  3378.8770 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 169 - Loss:  3592.7319 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 170 - Loss:  4247.9150 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 171 - Loss:  2683.9724 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 172 - Loss:  4076.3708 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 173 - Loss:  3593.3997 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 174 - Loss:  2706.2397 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 175 - Loss:  3551.1772 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 176 - Loss:  5502.0254 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 177 - Loss:  3724.8022 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 178 - Loss:  3499.9849 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 179 - Loss:  3560.3843 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 180 - Loss:  3114.4500 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 181 - Loss:  3079.7690 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 182 - Loss:  3707.9214 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 183 - Loss:  2651.3774 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 184 - Loss:  2604.4282 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 185 - Loss:  3073.1931 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 186 - Loss:  2541.2930 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 187 - Loss:  3101.0193 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 188 - Loss:  3567.5942 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 189 - Loss:  3347.8926 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 190 - Loss:  2877.1396 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 191 - Loss:  3000.6238 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 192 - Loss:  2510.4019 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 193 - Loss:  3137.6379 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 194 - Loss:  3258.5459 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 195 - Loss:  3282.9312 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 196 - Loss:  2527.7969 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 197 - Loss:  3691.1672 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 198 - Loss:  2723.2090 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 199 - Loss:  3877.0679 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 200 - Loss:  3119.7986 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 201 - Loss:  3501.9043 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 202 - Loss:  3906.2000 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 203 - Loss:  2608.1028 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 204 - Loss:  2454.0901 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 205 - Loss:  3034.0605 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 206 - Loss:  3014.2173 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 207 - Loss:  4085.5923 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 208 - Loss:  3087.3062 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 209 - Loss:  3788.7739 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 210 - Loss:  2917.7456 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 211 - Loss:  2859.0986 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 212 - Loss:  2631.7043 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 213 - Loss:  2850.8113 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 214 - Loss:  2067.3442 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 215 - Loss:  3023.5549 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 216 - Loss:  3441.2141 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 217 - Loss:  4941.0146 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 218 - Loss:  2716.7446 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 219 - Loss:  2693.7393 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 220 - Loss:  1817.6882 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 221 - Loss:  2955.5015 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 222 - Loss:  2765.7268 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 223 - Loss:  2449.4160 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 224 - Loss:  3152.0754 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 225 - Loss:  2670.9436 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 226 - Loss:  2796.0640 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 227 - Loss:  2732.7119 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 228 - Loss:  2854.1440 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 229 - Loss:  3045.3472 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 230 - Loss:  2572.9773 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 231 - Loss:  2800.5017 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 232 - Loss:  2625.8345 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 233 - Loss:  3086.2617 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 234 - Loss:  3736.8853 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 235 - Loss:  3237.9131 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 236 - Loss:  3780.9736 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 237 - Loss:  2833.7539 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 238 - Loss:  2724.3887 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 239 - Loss:  2768.0596 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 240 - Loss:  2457.9385 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 241 - Loss:  3382.9792 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 242 - Loss:  2015.8363 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 243 - Loss:  1787.6858 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 244 - Loss:  2678.7310 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 245 - Loss:  2465.2236 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 246 - Loss:  2320.4062 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 247 - Loss:  1968.2456 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 248 - Loss:  2521.7703 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 249 - Loss:  2359.3945 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 250 - Loss:  3125.8682 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 251 - Loss:  3263.3801 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 252 - Loss:  1887.9055 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 253 - Loss:  2480.8230 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 254 - Loss:  1664.2598 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 255 - Loss:  3444.2603 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 256 - Loss:  3036.7449 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 257 - Loss:  2356.4893 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 258 - Loss:  2684.2168 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 259 - Loss:  2856.8433 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 260 - Loss:  2519.5757 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 261 - Loss:  1968.1655 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 262 - Loss:  2486.5203 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 263 - Loss:  2407.8120 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 264 - Loss:  3255.0947 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 265 - Loss:  2697.9656 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 266 - Loss:  2916.5408 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 267 - Loss:  3323.6416 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 268 - Loss:  1999.5630 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 269 - Loss:  2851.0498 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 270 - Loss:  2288.3716 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 271 - Loss:  1898.8000 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 272 - Loss:  2616.4697 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 273 - Loss:  2944.5918 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 274 - Loss:  2612.1147 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 275 - Loss:  2709.9907 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 276 - Loss:  3456.5127 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 277 - Loss:  2076.5791 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 278 - Loss:  2853.9375 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 279 - Loss:  2969.1521 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 280 - Loss:  2380.0540 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 281 - Loss:  2763.8989 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 282 - Loss:  2635.2524 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 283 - Loss:  3013.3870 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 284 - Loss:  3053.8105 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 285 - Loss:  1800.0542 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 286 - Loss:  2815.3511 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 287 - Loss:  2427.3921 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 288 - Loss:  2556.2471 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 289 - Loss:  2403.2603 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 290 - Loss:  2541.5403 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 291 - Loss:  2472.9741 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 292 - Loss:  1984.5732 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 293 - Loss:  2750.7622 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 294 - Loss:  2288.5098 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 295 - Loss:  1981.6550 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 296 - Loss:  2542.1841 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 297 - Loss:  3269.2817 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 298 - Loss:  1866.3795 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 299 - Loss:  2337.8706 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 300 - Loss:  1503.3025 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 301 - Loss:  2102.0256 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 302 - Loss:  2103.9609 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 303 - Loss:  1593.1210 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 304 - Loss:  2725.9475 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 305 - Loss:  2929.5581 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 306 - Loss:  1974.5662 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 307 - Loss:  2079.5193 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 308 - Loss:  2695.2544 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 309 - Loss:  2234.7759 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 310 - Loss:  1549.4277 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 311 - Loss:  2248.6572 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 312 - Loss:  2031.3844 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 313 - Loss:  1750.4224 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 314 - Loss:  1377.7173 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 315 - Loss:  1856.2314 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 316 - Loss:  1664.5522 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 317 - Loss:  1852.5428 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 318 - Loss:  1931.3549 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 319 - Loss:  2098.8750 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 320 - Loss:  2319.3357 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 321 - Loss:  2234.8643 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 322 - Loss:  1773.4077 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 323 - Loss:  2091.8301 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 324 - Loss:  1992.4824 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 325 - Loss:  2414.7781 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 326 - Loss:  1934.4167 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 327 - Loss:  1941.5331 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 328 - Loss:  1891.8755 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 329 - Loss:  1950.6162 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 330 - Loss:  1968.9973 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 331 - Loss:  2015.3921 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 332 - Loss:  2109.5610 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 333 - Loss:  1863.9756 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 334 - Loss:  1757.6603 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 335 - Loss:  1705.6996 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 336 - Loss:  2647.7319 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 337 - Loss:  2642.7080 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 338 - Loss:  2799.7129 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 339 - Loss:  2380.3284 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 340 - Loss:  2104.4414 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 341 - Loss:  1509.0314 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 342 - Loss:  2138.1333 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 343 - Loss:  1873.1555 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 344 - Loss:  1692.1041 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 345 - Loss:  2139.3000 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 346 - Loss:  1885.4558 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 347 - Loss:  1939.3969 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 348 - Loss:  1579.9742 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 349 - Loss:  1133.7998 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 350 - Loss:  1807.2786 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 351 - Loss:  1472.5356 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 352 - Loss:  1747.9667 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 353 - Loss:  1778.2162 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 354 - Loss:  2697.2764 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 355 - Loss:  2291.1484 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 356 - Loss:  2239.8325 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 357 - Loss:  2835.8843 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 358 - Loss:  2256.8499 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 359 - Loss:  1744.0842 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 360 - Loss:  1693.0779 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 361 - Loss:  2104.3691 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 362 - Loss:  1834.9541 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 363 - Loss:  2316.3442 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 364 - Loss:  2467.0315 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 365 - Loss:  1485.1272 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 366 - Loss:  1564.2471 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 367 - Loss:  2229.0010 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 368 - Loss:  1755.5891 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 369 - Loss:  2742.1343 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 370 - Loss:  1819.1128 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 371 - Loss:  1888.6696 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 372 - Loss:  2453.8125 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 373 - Loss:  2526.7832 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 374 - Loss:  1919.6593 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 375 - Loss:  1740.2579 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 376 - Loss:  1805.0083 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 377 - Loss:  2190.5630 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 378 - Loss:  1925.3344 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 379 - Loss:  3162.7622 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 380 - Loss:  1680.4119 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 381 - Loss:  2041.0168 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 382 - Loss:  2335.2944 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 383 - Loss:  1781.7444 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 384 - Loss:  1890.5435 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 385 - Loss:  1746.8865 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 386 - Loss:  1728.0790 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 387 - Loss:  2562.5298 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 388 - Loss:  1752.4600 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 389 - Loss:  1983.2103 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 390 - Loss:  1688.7437 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 391 - Loss:  1837.6700 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 392 - Loss:  2440.7976 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 393 - Loss:  2345.8254 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 394 - Loss:  1615.6088 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 395 - Loss:  1881.3390 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 396 - Loss:  2202.7942 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 397 - Loss:  1739.3523 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 398 - Loss:  2861.9053 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 399 - Loss:  1633.7533 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 400 - Loss:  1731.4119 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 401 - Loss:  1926.6230 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 402 - Loss:  1457.9860 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 403 - Loss:  1450.8474 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 404 - Loss:  1277.8225 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 405 - Loss:  2126.8203 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 406 - Loss:  1287.0847 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 407 - Loss:  1457.7769 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 408 - Loss:  1946.2754 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 409 - Loss:  1682.7095 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 410 - Loss:  1131.5356 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 411 - Loss:  2016.7229 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 412 - Loss:  1961.6377 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 413 - Loss:  1415.0315 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 414 - Loss:  1691.7612 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 415 - Loss:  1513.1952 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 416 - Loss:  1919.8124 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 417 - Loss:  1459.6339 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 418 - Loss:  1583.0093 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 419 - Loss:  1707.1445 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 420 - Loss:  1088.0800 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 421 - Loss:   932.1483 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 422 - Loss:  1604.7478 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 423 - Loss:  1366.4192 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 424 - Loss:  1583.4270 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 425 - Loss:  1483.0911 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 426 - Loss:  1234.6378 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 427 - Loss:  1028.7957 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 428 - Loss:  2002.1320 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 429 - Loss:  1722.1284 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch   1 - Loss:  1971.9376 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch   2 - Loss:  1469.3965 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch   3 - Loss:  2056.1157 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch   4 - Loss:  1417.4637 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch   5 - Loss:  1392.4869 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch   6 - Loss:  1966.5059 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch   7 - Loss:  1963.0688 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch   8 - Loss:  1869.2433 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch   9 - Loss:  1848.7462 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  10 - Loss:  2013.0311 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  11 - Loss:  1877.5582 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  12 - Loss:  1840.7205 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  13 - Loss:  1392.6562 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  14 - Loss:  1504.0387 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  15 - Loss:  1403.3119 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  16 - Loss:  1138.3746 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  17 - Loss:  1650.1857 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  18 - Loss:  1140.5864 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  19 - Loss:  1432.2910 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  20 - Loss:  1831.3419 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  21 - Loss:  1140.7961 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  22 - Loss:  1423.5795 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  23 - Loss:  2512.0273 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  24 - Loss:  1342.6936 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  25 - Loss:  1307.9016 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  26 - Loss:  1976.0490 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  27 - Loss:  2527.7769 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  28 - Loss:  1690.1576 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  29 - Loss:  1866.9956 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  30 - Loss:  1845.9952 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  31 - Loss:  1254.3605 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  32 - Loss:  1596.5911 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  33 - Loss:  1397.2493 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  34 - Loss:  1475.9125 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  35 - Loss:  1433.3595 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  36 - Loss:  2096.8540 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  37 - Loss:  1227.0259 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  38 - Loss:  1911.5752 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  39 - Loss:  1912.9263 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  40 - Loss:  1816.0238 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  41 - Loss:  1777.8997 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  42 - Loss:  1475.9548 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  43 - Loss:  1328.6106 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  44 - Loss:  2097.8904 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  45 - Loss:  1078.9417 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  46 - Loss:  1366.0084 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  47 - Loss:  1711.9480 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  48 - Loss:  1704.6365 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  49 - Loss:  1627.2883 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  50 - Loss:  1338.3699 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  51 - Loss:  1108.4822 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  52 - Loss:  1225.3285 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  53 - Loss:  1366.9395 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  54 - Loss:  1523.6289 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  55 - Loss:  1653.8973 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  56 - Loss:  2090.8245 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  57 - Loss:  2230.1594 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  58 - Loss:  1421.2339 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  59 - Loss:  1803.1716 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  60 - Loss:  1682.0767 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  61 - Loss:  1454.7968 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  62 - Loss:  1610.2399 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  63 - Loss:   933.3251 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  64 - Loss:  1561.4971 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  65 - Loss:  1364.4038 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  66 - Loss:  1274.1392 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  67 - Loss:  1954.6614 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  68 - Loss:  1358.5699 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  69 - Loss:  1882.5804 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  70 - Loss:  1602.3772 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  71 - Loss:  1242.3079 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  72 - Loss:  1009.6929 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  73 - Loss:  2170.0735 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  74 - Loss:  1446.4216 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  75 - Loss:  1702.5425 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  76 - Loss:  1522.9099 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  77 - Loss:  1347.3540 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  78 - Loss:  1881.4900 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  79 - Loss:  1070.3760 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  80 - Loss:  1997.2415 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  81 - Loss:  1657.2423 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  82 - Loss:   814.3074 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  83 - Loss:  1927.5327 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  84 - Loss:  1579.5420 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  85 - Loss:  1485.3446 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  86 - Loss:  1443.3961 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  87 - Loss:  1147.2576 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  88 - Loss:  1312.1902 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  89 - Loss:  1897.1404 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  90 - Loss:  1314.4091 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  91 - Loss:  1186.1140 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  92 - Loss:  1454.7057 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch  93 - Loss:  1743.8005 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  94 - Loss:  1497.0950 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  95 - Loss:  1634.7200 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  96 - Loss:   979.7360 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  97 - Loss:  2504.7163 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch  98 - Loss:  1676.4607 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  99 - Loss:  1654.0686 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 100 - Loss:  1610.8054 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 101 - Loss:  1370.1580 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 102 - Loss:  1395.3242 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 103 - Loss:  2072.9897 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 104 - Loss:  1230.0140 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 105 - Loss:  1026.9465 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 106 - Loss:  1260.2786 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 107 - Loss:  1442.5776 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 108 - Loss:  1484.9440 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 109 - Loss:  1805.7554 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 110 - Loss:  1455.4399 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 111 - Loss:  1252.5228 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 112 - Loss:  1557.3215 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 113 - Loss:  1797.5212 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 114 - Loss:  1407.0044 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 115 - Loss:  1229.9685 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 116 - Loss:  1121.7018 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 117 - Loss:  1092.8542 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 118 - Loss:  1651.8285 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 119 - Loss:   962.3546 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 120 - Loss:  1321.7076 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 121 - Loss:  1857.6794 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 122 - Loss:  2240.0620 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 123 - Loss:  1158.0508 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 124 - Loss:  1122.1013 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 125 - Loss:  1736.7185 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 126 - Loss:  1071.7875 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 127 - Loss:   964.5037 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 128 - Loss:  1402.0105 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 129 - Loss:  1600.6698 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 130 - Loss:  1450.9071 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 131 - Loss:  1073.3390 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 132 - Loss:  1126.8127 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 133 - Loss:   974.0596 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 134 - Loss:  1193.4968 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 135 - Loss:  1524.6840 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 136 - Loss:  1748.1753 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 137 - Loss:  2026.0771 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 138 - Loss:  1509.1265 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 139 - Loss:  1498.4901 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 140 - Loss:  1378.9877 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 141 - Loss:  1126.1973 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 142 - Loss:  1471.3098 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 143 - Loss:  1221.0952 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 144 - Loss:  1156.5465 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 145 - Loss:  1454.0076 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 146 - Loss:  1133.2784 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 147 - Loss:  1023.0353 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 148 - Loss:  1145.7407 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 149 - Loss:  1676.8352 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 150 - Loss:  1094.7123 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 151 - Loss:  1212.7134 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 152 - Loss:  1381.7675 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 153 - Loss:  1148.9758 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 154 - Loss:  1911.1731 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 155 - Loss:  1026.3142 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 156 - Loss:  1502.8604 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 157 - Loss:  1603.4312 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 158 - Loss:  1415.6826 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 159 - Loss:  1510.5907 Validation Accuracy: 0.804688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6539dff9b409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y:batch_y, keep_prob: dropout})\n",
    "            \n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y:batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.\n",
    "            })\n",
    "            \n",
    "            print('Epoch {:>2}, Batch {:>3} - '\n",
    "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                    epoch + 1,\n",
    "                    batch + 1,\n",
    "                    loss,\n",
    "                    valid_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
